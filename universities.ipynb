{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columbia University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cu():\n",
    "    path = 'Columbia University'\n",
    "    existed=os.path.exists(path)\n",
    "    if not existed:\n",
    "        os.makedirs(path)\n",
    "        \n",
    "    cu = pd.read_excel('Columbia University.xls')\n",
    "    for i in range(len(cu)):\n",
    "        website = cu.iloc[i]['website']\n",
    "        original_url = website.replace('detail', 'photo')\n",
    "        staff_id = website[51:]\n",
    "        res = requests.get(original_url)\n",
    "        redirected_url = res.url\n",
    "\n",
    "        last_dot_index = redirected_url[::-1].index(\".\")\n",
    "        suffix = redirected_url[-last_dot_index-1:]\n",
    "        img = res.content\n",
    "        with open(path+'/'+staff_id+suffix, 'wb') as f:\n",
    "            try:\n",
    "                f.write(img)       \n",
    "            except IOError as e:\n",
    "                print(e)\n",
    "\n",
    "        cu.loc[i, 'iconUrl'] = redirected_url\n",
    "    \n",
    "    cu.to_excel(path+'/sheet.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Harvard University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hu():\n",
    "    path = 'Harvard University'\n",
    "    existed=os.path.exists(path)\n",
    "    if not existed:\n",
    "        os.makedirs(path)\n",
    "        \n",
    "    hu = pd.read_excel('Harvard University.xls')\n",
    "    for i in range(len(hu)):\n",
    "        website = hu.iloc[i]['website']\n",
    "        facId = website[website.index(\"=\")+1:]\n",
    "        img_url = \"http://sands.hbs.edu/photos/facstaff/Ent\"+ facId + \".jpg\"\n",
    "        res = requests.get(img_url)\n",
    "        img = res.content\n",
    "        with open(path+'/'+facId+\".jpg\", 'wb') as f:\n",
    "            try:\n",
    "                f.write(img)       \n",
    "            except IOError as e:\n",
    "                print(e)\n",
    "\n",
    "        hu.loc[i, 'iconUrl'] = img_url\n",
    "    \n",
    "    hu.to_excel(path+'/sheet.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_hu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Massachusetts Institute of Technology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mit():\n",
    "    path = 'Massachusetts Institute of Technology'\n",
    "    existed=os.path.exists(path)\n",
    "    if not existed:\n",
    "        os.makedirs(path)\n",
    "    \n",
    "    mit = pd.read_excel('Massachusetts Institute of Technology.xls')\n",
    "    for i in range(len(mit)):\n",
    "        website = mit.iloc[i]['website']\n",
    "        if type(website) == type(''):\n",
    "            continue\n",
    "            \n",
    "        name = mit.iloc[i]['name']\n",
    "        name = name.replace('.', '')\n",
    "        name = name.split(', ')\n",
    "        name.reverse()\n",
    "        name = '-'.join(name)\n",
    "\n",
    "        website = 'https://mitsloan.mit.edu/faculty/directory/' + name.lower().replace(\" \", \"-\")\n",
    "\n",
    "        mit.loc[i, 'website'] = website\n",
    "        \n",
    "        res = requests.get(website)\n",
    "        soup = BeautifulSoup(res.text, 'lxml')\n",
    "        element = soup.select_one('#main-content > div.page-profile-detail > header > div > div.page-profile-detail__header-person-image-container > img')\n",
    "        if element is None:\n",
    "            continue\n",
    "        \n",
    "        img_url = element.attrs['src']\n",
    "        img_url = 'https://mitsloan.mit.edu' + img_url #! important\n",
    "        \n",
    "        res = requests.get(img_url)\n",
    "        img = res.content\n",
    "        file_name = mit.iloc[i]['name']\n",
    "        with open(path+'/'+file_name+\".png\", 'wb') as f:\n",
    "            try:\n",
    "                f.write(img)       \n",
    "            except IOError as e:\n",
    "                print(e)\n",
    "\n",
    "        mit.loc[i, 'iconUrl'] = img_url\n",
    "    \n",
    "    mit.to_excel(path+'/sheet.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_mit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stanford University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_su():\n",
    "    path = 'Stanford University'\n",
    "    existed=os.path.exists(path)\n",
    "    if not existed:\n",
    "        os.makedirs(path)\n",
    "        \n",
    "    su = pd.read_excel('Stanford University.xls')\n",
    "    for i in range(len(su)):\n",
    "        website = su.iloc[i]['website']\n",
    "        res = requests.get(website)\n",
    "        soup = BeautifulSoup(res.text, 'lxml')\n",
    "        element = soup.select_one(\"#block-system-main > div > div > div.group-left > div.field.field-name-field-image-single-public.field-type-image.field-label-hidden > div > div > img\")\n",
    "        if element is None:\n",
    "            continue\n",
    "        \n",
    "        img_url = element.attrs['src']\n",
    "        last_dot_index = website[::-1].index(\"/\")\n",
    "        name = website[-last_dot_index:]\n",
    "        \n",
    "        res = requests.get(img_url)\n",
    "        img = res.content\n",
    "        with open(path+'/'+name+\".jpg\", 'wb') as f:\n",
    "            try:\n",
    "                f.write(img)       \n",
    "            except IOError as e:\n",
    "                print(e)\n",
    "\n",
    "        su.loc[i, 'iconUrl'] = img_url\n",
    "    \n",
    "    su.to_excel(path+'/sheet.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_su()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## University of California, Berkeley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ucb():\n",
    "    path = 'University of California, Berkeley'\n",
    "    existed=os.path.exists(path)\n",
    "    if not existed:\n",
    "        os.makedirs(path)\n",
    "    \n",
    "    ucb = pd.read_excel('University of California, Berkeley.xls')\n",
    "\n",
    "    for i in range(len(ucb)):\n",
    "\n",
    "        name = ucb.iloc[i]['name']\n",
    "        name = name.lower().replace(' ', '+')\n",
    "        \n",
    "        website = 'https://haas.berkeley.edu/faculty/?area=&keywords=' + name + '&action=faculty-search' \n",
    "\n",
    "        headers = {'Accept': 'text/html, application/xhtml+xml, image/jxr, */*',\n",
    "               'Accept - Encoding':'gzip, deflate',\n",
    "               'Accept-Language':'zh-Hans-CN, zh-Hans; q=0.5',\n",
    "               'Connection':'Keep-Alive',\n",
    "               'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36 Edge/15.15063'}\n",
    "        res = requests.get(website, headers=headers)\n",
    "        \n",
    "        soup = BeautifulSoup(res.text, 'lxml')\n",
    "        element = soup.select_one('#page-content > div > div > div.col-xs-12.col-lg-10.col-content.padded-main-content > div > div.grid.grid-size-smaller > a:nth-child(1)')\n",
    "\n",
    "        if element is None:\n",
    "            continue\n",
    "        href = element.attrs['href']\n",
    "       \n",
    "\n",
    "        if type(ucb.iloc[i]['website']) != type(''):\n",
    "            ucb.loc[i, 'website'] = href\n",
    "\n",
    "        res = requests.get(href, headers=headers)\n",
    "        soup = BeautifulSoup(res.text, 'lxml')\n",
    "        element = soup.select_one('#sidebar > div.widget.hidden-lg-down > div > img')\n",
    "\n",
    "        if element is None:\n",
    "            continue\n",
    "        \n",
    "        img_url = element.attrs['src']\n",
    "       \n",
    "        res = requests.get(img_url, headers=headers)\n",
    "        img = res.content\n",
    "        file_name = ucb.iloc[i]['name']\n",
    "        with open(path+'/'+file_name+\".jpg\", 'wb') as f:\n",
    "            try:\n",
    "                f.write(img)       \n",
    "            except IOError as e:\n",
    "                print(e)\n",
    "\n",
    "        ucb.loc[i, 'iconUrl'] = img_url\n",
    "    \n",
    "    ucb.to_excel(path+'/sheet.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ucb()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## University of Cambridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cambridge():\n",
    "    path = 'University of Cambridge'\n",
    "    existed=os.path.exists(path)\n",
    "    if not existed:\n",
    "        os.makedirs(path)\n",
    "        \n",
    "    cambridge = pd.read_excel('University of Cambridge.xls')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## University of Chicago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uc():\n",
    "    path = 'University of Chicago'\n",
    "    existed=os.path.exists(path)\n",
    "    if not existed:\n",
    "        os.makedirs(path)\n",
    "        \n",
    "    uc = pd.read_excel('University of Chicago.xls')\n",
    "    for i in range(len(uc)):\n",
    "\n",
    "        name = uc.iloc[i]['name']\n",
    "        name = name.lower().replace('.', '').replace(' ', '-')\n",
    "        prefix = name.split('-')[-1][:1]\n",
    "        \n",
    "        website = 'https://www.chicagobooth.edu/faculty/directory/' + prefix + '/' + name\n",
    "\n",
    "        if type(uc.iloc[i]['website']) != type(''):\n",
    "            uc.loc[i, 'website'] = website\n",
    "            \n",
    "      \n",
    "        res = requests.get(website)\n",
    "        \n",
    "        soup = BeautifulSoup(res.text, 'lxml')\n",
    "        element = soup.select_one('#ContentPlaceHolder1_content_imgImageFeed')\n",
    "\n",
    "        if element is None:\n",
    "            continue\n",
    "        \n",
    "        img_url = element.attrs['src']\n",
    "        \n",
    "        \n",
    "       \n",
    "        res = requests.get(img_url)\n",
    "        img = res.content\n",
    "        file_name = uc.iloc[i]['name']\n",
    "        with open(path+'/'+file_name+\".jpg\", 'wb') as f:\n",
    "            try:\n",
    "                f.write(img)       \n",
    "            except IOError as e:\n",
    "                print(e)\n",
    "\n",
    "        uc.loc[i, 'iconUrl'] = img_url\n",
    "    \n",
    "    uc.to_excel(path+'/sheet.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_uc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## University of Oxford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ox():\n",
    "    path = 'University of Oxford'\n",
    "    existed=os.path.exists(path)\n",
    "    if not existed:\n",
    "        os.makedirs(path)\n",
    "        \n",
    "    ox = pd.read_excel('University of Oxford.xls')\n",
    "    for i in range(len(ox)):\n",
    "        website = ox.iloc[i]['website']\n",
    "\n",
    "        res = requests.get(website)\n",
    "        soup = BeautifulSoup(res.text, 'lxml')\n",
    "        element = soup.select_one('#main > div > section > div.region.region-content > article > div > div > div.row > div.col-xs-9.col-sm-5 > div > picture > img')\n",
    "        if element is None:\n",
    "            continue\n",
    "        \n",
    "        img_url = element.attrs['src']\n",
    "        img_url = 'https://www.sbs.ox.ac.uk' + img_url #! important\n",
    "        \n",
    "        res = requests.get(img_url)\n",
    "        img = res.content\n",
    "        file_name = ox.iloc[i]['name']\n",
    "        with open(path+'/'+file_name+\".jpg\", 'wb') as f:\n",
    "            try:\n",
    "                f.write(img)       \n",
    "            except IOError as e:\n",
    "                print(e)\n",
    "\n",
    "        ox.loc[i, 'iconUrl'] = img_url\n",
    "    \n",
    "    ox.to_excel(path+'/sheet.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ox()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## University of Pennsylvania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_up():\n",
    "    path = 'University of Pennsylvania'\n",
    "    existed=os.path.exists(path)\n",
    "    if not existed:\n",
    "        os.makedirs(path)\n",
    "    \n",
    "    up = pd.read_excel('./University of Pennsylvania/sheet.xls')\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    for i in range(263, 271):\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            print(\"{:3d}\".format(i // 50), end=\": \")\n",
    "        print(i % 50, end=\" \")\n",
    "        if i % 50 == 49:\n",
    "            print()\n",
    "\n",
    "        name = up.iloc[i]['name']\n",
    "               \n",
    "        \n",
    "#         option = webdriver.ChromeOptions()\n",
    "#         option.add_argument('headless')\n",
    "#         driver = webdriver.Chrome(chrome_options=option)\n",
    "\n",
    "    \n",
    "        driver.get('https://www.upenn.edu/searchdir')\n",
    "        search_input = driver.find_element_by_xpath('//*[@id=\"keywords\"]')\n",
    "        search_input.click()\n",
    "        search_input.send_keys(name)\n",
    "        \n",
    "        driver.find_element_by_xpath('//*[@id=\"block-system-main\"]/div[1]/form/button').click()\n",
    "        time.sleep(5)\n",
    "        item = driver.find_element_by_xpath('//*[@id=\"___gcse_0\"]/div/div/div/div[5]/div[2]/div/div/div[1]/div[1]/div[1]/div/a')\n",
    "        website = item.get_attribute('href')\n",
    "        up.loc[i, 'website'] = website\n",
    "        up.to_excel(path+'/sheet.xls')\n",
    "        \n",
    "        res = requests.get(website)\n",
    "        soup = BeautifulSoup(res.text, 'lxml')\n",
    "        element = soup.select_one('#main > div.wfp-primary-content > div.wfp-header > div:nth-child(2) > div > img')\n",
    "        if element is None:\n",
    "            print(name, i)\n",
    "            continue\n",
    "        \n",
    "        img_url = element.attrs['src']\n",
    "    \n",
    "        res = requests.get(img_url)\n",
    "        img = res.content\n",
    "        file_name = up.iloc[i]['name']\n",
    "        with open(path+'/'+file_name+\".jpg\", 'wb') as f:\n",
    "            try:\n",
    "                f.write(img)       \n",
    "            except IOError as e:\n",
    "                print(e)\n",
    "\n",
    "        up.loc[i, 'iconUrl'] = img_url\n",
    "    \n",
    "    up.to_excel(path+'/sheet.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_up()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yale University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yl():\n",
    "    path = 'Yale University'\n",
    "    existed=os.path.exists(path)\n",
    "    if not existed:\n",
    "        os.makedirs(path)\n",
    "        \n",
    "    yl = pd.read_excel('Yale University/sheet.xls')\n",
    "    for i in range(len(yl)):\n",
    "        if type(yl.iloc[i]['iconUrl']) == type(''):\n",
    "            continue\n",
    "        \n",
    "        name = yl.iloc[i]['name']\n",
    "        name = name.replace('.', '').replace(' ','-')\n",
    "        name = name.lower()\n",
    "        website = \"https://som.yale.edu/faculty/\"+ name\n",
    "        \n",
    "        res = requests.get(website)\n",
    "        \n",
    "        soup = BeautifulSoup(res.text, 'lxml')\n",
    "        element = soup.select_one('.faculty--image img')\n",
    "        \n",
    "        if element is None:\n",
    "            continue\n",
    "        img_url = element.attrs['src']\n",
    "       \n",
    "\n",
    "        if type(yl.iloc[i]['website']) != type(''):\n",
    "            yl.loc[i, 'website'] = website\n",
    "\n",
    "        res = requests.get(img_url)\n",
    "        img = res.content\n",
    "        file_name = yl.iloc[i]['name']\n",
    "        with open(path+'/'+file_name+\".jpg\", 'wb') as f:\n",
    "            try:\n",
    "                f.write(img)       \n",
    "            except IOError as e:\n",
    "                print(e)\n",
    "\n",
    "        yl.loc[i, 'iconUrl'] = img_url\n",
    "    \n",
    "    yl.to_excel(path+'/sheet.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_yl()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
